{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_9892/315726294.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mre\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mTokenizer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msequence\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpad_sequences\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Embedding, LSTM, SpatialDropout1D\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original_text</th>\n",
       "      <th>source</th>\n",
       "      <th>pornografi</th>\n",
       "      <th>sara</th>\n",
       "      <th>radikalisme</th>\n",
       "      <th>pencemaran_nama_baik</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.BUKAN CM SPANDUK PROF,VIDEO2 ORASI MEREKA, B...</td>\n",
       "      <td>twitter</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@memeqbeceq gy sange'gatel yh tetek'memekY drn...</td>\n",
       "      <td>twitter</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Pertama kali denger lagunya enk bgt in dan png...</td>\n",
       "      <td>instagram</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>astajim, ini pasti yg kasih penghargaan ke ibu...</td>\n",
       "      <td>kaskus</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>beda kalo disini kalo komplain lgs di bully am...</td>\n",
       "      <td>kaskus</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       original_text     source  pornografi  \\\n",
       "0  1.BUKAN CM SPANDUK PROF,VIDEO2 ORASI MEREKA, B...    twitter         0.0   \n",
       "1  @memeqbeceq gy sange'gatel yh tetek'memekY drn...    twitter         1.0   \n",
       "2  Pertama kali denger lagunya enk bgt in dan png...  instagram         0.0   \n",
       "3  astajim, ini pasti yg kasih penghargaan ke ibu...     kaskus         0.0   \n",
       "4  beda kalo disini kalo komplain lgs di bully am...     kaskus         0.0   \n",
       "\n",
       "   sara  radikalisme  pencemaran_nama_baik  \n",
       "0   0.0          1.0                   0.0  \n",
       "1   0.0          0.0                   0.0  \n",
       "2   0.0          0.0                   0.0  \n",
       "3   0.0          0.0                   0.0  \n",
       "4   0.0          0.0                   0.0  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ambil link project\n",
    "url = 'https://raw.githubusercontent.com/harazukukaromi/ML-capbatu/main/datatest_superfix%20-%20Sheet2.csv'\n",
    "dataset = pd.read_csv(url)\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original_text</th>\n",
       "      <th>source</th>\n",
       "      <th>pornografi</th>\n",
       "      <th>sara</th>\n",
       "      <th>radikalisme</th>\n",
       "      <th>pencemaran_nama_baik</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1014</th>\n",
       "      <td>Ga bakalan bro</td>\n",
       "      <td>twitter</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1015</th>\n",
       "      <td>KELAKUAN bodoh USER masuk KATEGORI perbuatan T...</td>\n",
       "      <td>twitter</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1016</th>\n",
       "      <td>Monyet Turun ke Pemukiman Warga Cibadak Sukabu...</td>\n",
       "      <td>twitter</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1017</th>\n",
       "      <td>\"USER Kotor ga masalah yang penting bahagia wa...</td>\n",
       "      <td>twitter</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1018</th>\n",
       "      <td>mau giveaway taplak meja tapi nanti yang menan...</td>\n",
       "      <td>twitter</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          original_text   source  pornografi  \\\n",
       "1014                                     Ga bakalan bro  twitter         0.0   \n",
       "1015  KELAKUAN bodoh USER masuk KATEGORI perbuatan T...  twitter         0.0   \n",
       "1016  Monyet Turun ke Pemukiman Warga Cibadak Sukabu...  twitter         0.0   \n",
       "1017  \"USER Kotor ga masalah yang penting bahagia wa...  twitter         0.0   \n",
       "1018  mau giveaway taplak meja tapi nanti yang menan...  twitter         0.0   \n",
       "\n",
       "      sara  radikalisme  pencemaran_nama_baik  \n",
       "1014   0.0          0.0                   0.0  \n",
       "1015   0.0          0.0                   1.0  \n",
       "1016   0.0          0.0                   0.0  \n",
       "1017   0.0          1.0                   1.0  \n",
       "1018   0.0          0.0                   0.0  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1.bukan cm spanduk prof,video2 orasi mereka, b...\n",
       "1    @memeqbeceq gy sange'gatel yh tetek'memeky drn...\n",
       "2    pertama kali denger lagunya enk bgt in dan png...\n",
       "3    astajim, ini pasti yg kasih penghargaan ke ibu...\n",
       "4    beda kalo disini kalo komplain lgs di bully am...\n",
       "Name: original_text, dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Change text to lowercase\n",
    "def proses_data(text):\n",
    "    newText = text.lower()\n",
    "    return newText\n",
    "#dataset['original_text'].apply(lambda x: proses_data(x))#(ini case kalau semua mau ngerun semua data Komputerku kentang maka ngefreeze)\n",
    "testData = dataset['original_text']\n",
    "testData = testData.apply(lambda x: proses_data(x))\n",
    "testData.head()\n",
    "#dataset.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1.bukan cm spanduk prof,video2 orasi mereka, b...\n",
       "1    @memeqbeceq gy sange'gatel yh tetek'memeky drn...\n",
       "2    pertama kali denger lagunya enk bgt in dan png...\n",
       "3    astajim, ini pasti yg kasih penghargaan ke ibu...\n",
       "4    beda kalo disini kalo komplain lgs di bully am...\n",
       "Name: original_text, dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#menghilangkan link dan tag html\n",
    "def link_remover(text):\n",
    "    url_regex = re.compile(r'(http|ftp|https)://([\\w_-]+(?:(?:\\.[\\w_-]+)+))([\\w.,@?^=%&:/~+#-]*[\\w@?^=%&/~+#-])?')\n",
    "    return url_regex.sub('', text)\n",
    "testData = testData.apply(lambda x: link_remover(x))\n",
    "testData.head()\n",
    "#dataset = dataset['original_text'].apply(lambda x: link_remover(x))\n",
    "#dataset.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1.bukan cm spanduk prof,video2 orasi mereka, b...\n",
       "1      gy sange'gatel yh tetek'memeky drnjng tmpt t...\n",
       "2    pertama kali denger lagunya enk bgt in dan png...\n",
       "3    astajim, ini pasti yg kasih penghargaan ke ibu...\n",
       "4    beda kalo disini kalo komplain lgs di bully am...\n",
       "Name: original_text, dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#menghilangkan kalimat bersama @name\n",
    "def name_remover(text):\n",
    "    name_regex = re.compile(r'@[\\w_-]+')\n",
    "    return name_regex.sub(' ', text)\n",
    "testData = testData.apply(lambda x: name_remover(x))\n",
    "testData.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1 bukan cm spanduk prof video2 orasi mereka  b...\n",
       "1      gy sange gatel yh tetek memeky drnjng tmpt t...\n",
       "2    pertama kali denger lagunya enk bgt in dan png...\n",
       "3    astajim  ini pasti yg kasih penghargaan ke ibu...\n",
       "4    beda kalo disini kalo komplain lgs di bully am...\n",
       "Name: original_text, dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# menghilangkan tanda baca dan karakter spesial\n",
    "def karakter_spesial(text):\n",
    "    newText = re.sub('[^a-zA-Z0-9\\s]', ' ', text)\n",
    "    return newText\n",
    "testData = testData.apply(lambda x: karakter_spesial(x))\n",
    "testData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     bukan cm spanduk prof video orasi mereka  buk...\n",
       "1      gy sange gatel yh tetek memeky drnjng tmpt t...\n",
       "2    pertama kali denger lagunya enk bgt in dan png...\n",
       "3    astajim  ini pasti yg kasih penghargaan ke ibu...\n",
       "4    beda kalo disini kalo komplain lgs di bully am...\n",
       "Name: original_text, dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# menghilang angka yang nempel dengan kalimat\n",
    "def angka_berlebihan(text):\n",
    "    newText = re.sub('[0-9]', '', text)\n",
    "    return newText\n",
    "testData = testData.apply(lambda x: angka_berlebihan(x))\n",
    "testData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    bukan cm spanduk prof video orasi mereka  buku...\n",
       "1    gy sange gatel yh tetek memeky drnjng tmpt tdr...\n",
       "2    pertama kali denger lagunya enk bgt in dan png...\n",
       "3    astajim  ini pasti yg kasih penghargaan ke ibu...\n",
       "4    beda kalo disini kalo komplain lgs di bully am...\n",
       "Name: original_text, dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# menghilangkan spasi berlebihan\n",
    "def Spasi_berlebihan(text):  \n",
    "    newText = re.sub('\\s+', '', text)\n",
    "    newText = re.sub('^\\s+', '', text)\n",
    "    return newText\n",
    "testData = testData.apply(lambda x: Spasi_berlebihan(x))\n",
    "testData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    829\n",
       "1.0    189\n",
       "Name: pornografi, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test menampilkan data\n",
    "dataset['pornografi'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    868\n",
       "1.0    150\n",
       "Name: sara, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['sara'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    852\n",
       "1.0    166\n",
       "Name: radikalisme, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['radikalisme'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    654\n",
       "1.0    363\n",
       "Name: pencemaran_nama_baik, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['pencemaran_nama_baik'].value_counts()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ce76555b2e0f32f585265c59f0c11de7853546a2a23013bd4aaeca5b3a95b77e"
  },
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
